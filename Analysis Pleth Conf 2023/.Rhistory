#Why was x3 chosen?
plot(x3,y,pch=19)
#But we know that AIC can retain more complex models. Let's use AICc.
dredge(reg,rank = "AICc") #MUCH better...but best model is still often nonsense, although only small deltAIC from intercept
#What if we use BIC?
dredge(reg,rank = "BIC") #Also much better
#What if we don't include an intercept only model, which many people advocate for including in our department.
dredge(reg,rank = "AICc",m.lim=c(1,3))
####################
loocv.err123=cv.glm(data, glm(y~.,data=data))
loocv.err1=cv.glm(data, glm(y~x1,data=data))
loocv.err2=cv.glm(data, glm(y~x2,data=data))
loocv.err3=cv.glm(data, glm(y~x3,data=data))
loocv.err12=cv.glm(data, glm(y~x1 + x2,data=data))
loocv.err13=cv.glm(data, glm(y~x1 + x3,data=data))
loocv.err23=cv.glm(data, glm(y~x2 + x3,data=data))
loocv.err0=cv.glm(data, glm(y~1,data=data))
loocv.err123$delta[1] #delta[1] is prediction error. delta[2] is the adjust crossvalidation estimate
loocv.err1$delta[1]
loocv.err2$delta[1]
loocv.err3$delta[1]
loocv.err12$delta[1]
loocv.err13$delta[1]
loocv.err23$delta[1]
loocv.err0$delta[1]
#Simple and elegant if (1) predictors not correlated, and (2) there are not too many of them.
summary(reg)
##run this code over and over
y <- rnorm(n, mean = a, sd = sdy)
x1=runif(n)
x2=runif(n)
x3=runif(n)
data=data.frame(y,x1,x2,x3)
reg=lm(y~.,data=data)
summary(reg)
dredge(reg,rank = "AICc")
#Answer, sometimes there is Type 1 error.
#But (1) not nearly as often as with AIC, even though people *think* AIC is more immune to this
#And (2) when type I error occurs with p-values it ALSO occurs with AIC, even corrected AIC
#Let's formalize this
######################
nummodels=500
pstor=rep(NA,nummodels)
AICstor=rep(NA,nummodels)
AICcstor=rep(NA,nummodels)
BICstor=rep(NA,nummodels)
y<-rnorm(1000)
x1<-rnorm(1000)
x2<-rnorm(1000)
model_intercept <- lm(y~1)
model_x1 <- lm(y~x1)
model_x2 <- lm(y~x2)
model_x1_x2 <- lm(y~x1+x2)
dredge(model_x1_x2, rank="AIC")
dredge(model_x1_x2, rank="BIC")
model_intercept <- lm(y~1)
model_x1 <- lm(y~x1)
model_x2 <- lm(y~x2)
model_x1_x2 <- lm(y~x1+x2)
dredge(model_x1_x2, rank="AIC")
dredge(model_x1_x2, rank="BIC")
install.packages("nimble")
library(nimble)
rm(list=ls())
setwd("C:/Users/jasmi/OneDrive/Documents/OSU/MS Docs/OSS 2023 Initial Data Analysis")
library(nimble)
library(ggplot2)
library(data.table)
library(tidyverse)
library(mcmcplots)
library(MCMCvis)
library(boot)
source('attach.nimble_v2.R')
## Load Data--------------------------------------------------------------------------------------------------------
data <- read.csv("sitecovs_obs_long.csv")
data$site <- as.numeric(data$site)
data$all.obs <- as.numeric(data$all.obs)
data$oss.obs <- as.numeric(data$oss.obs)
data$enes.obs <- as.numeric(data$enes.obs)
data2 <- read.csv("site_treatments.csv")
data2$site <- as.numeric(data2$site)
data2$treatment <- as.numeric(factor(data2$treatment))
scaled_temp <- c(scale(data$temp))
## Build Model--------------------------------------------------------------------------------------------------------
all.spp.model.1 <- nimbleCode ({
# Priors
for(t in 1:n.treatments){
TreatmentIntercept[t] ~ dunif(-10,10)
}#t
DetectionIntercept ~ dunif(-5,5)
betaTemp ~ dunif(-5, 5)
betaTemp2 ~ dunif(-5, 5)
# Likelihood
# Process/Biological model = Occupancy
# need two pieces: one defining psi and covariates, and one defining z dist
for(i in 1:n.sites) {
logit(psi[i]) <- TreatmentIntercept[treatment[i]]  #psi=occupancy probability
z[i] ~ dbern(psi[i])  # z=1 if occupied, z=latent true occupancy
}#i
# Observation model = Detection
# need two pieces: one for det coeff and one defining Y distribution
for(j in 1:n.obs) {
logit(p[j]) <- DetectionIntercept + betaTemp*temp[j] + betaTemp2*temp[j]^2
#p=detection probability for site i and survey j
Y[j] ~ dbern(p[j] * z[site[j]]) #Y=my actual data observations
#z=1 or 0, turns this on or off
}#j
})
# Parameters monitored
parameters <- c("z","p","TreatmentIntercept","DetectionIntercept","betaTemp","betaTemp2")
# MCMC Settings
ni <- 40000
nt <- 40
nb <- 20000
nc <- 3
# Data
nimble.data = list(Y=data$all.obs,
temp=scaled_temp)
nimble.constants = list(n.sites = length(unique(data$site)),
n.treatments = length(unique(data2$treatment)),
treatment=data2$treatment,
site=as.numeric(as.factor(data$site)),
n.obs = length(data$all.obs))
mcmc.output.1 <- nimbleMCMC(code = all.spp.model.1,
data = nimble.data,
constants=nimble.constants,
monitors = parameters,
niter = ni,
nburnin = nb,
nchains = nc,
thin=nt,
summary=TRUE,
samplesAsCodaMCMC = TRUE)
save(mcmc.output.1, file="./bayes_final_model.RData")
load("./bayes_final_model.RData")
attach.nimble(mcmc.output.1$samples)
# Inverse logit the detection intercept to get detection probabilities
det.probs.inv <- inv.logit(DetectionIntercept)
betaTemp <- betaTemp[,-2]
betaTemp <- as.matrix(betaTemp)
# Create vector of temp values for x-axis
range(data$temp)
temp.vect = c(30:85)
# Scale values the same way as in model
#temp.vect.scaled = c(scale(temp.vect))
# Make empty matrix for ??? draws over 469 surveys?
matrix <- matrix(NA, nrow=1500, ncol=56)
# Create count predictions for each temp
for (j in seq_along(temp.vect.scaled)) {
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
matrix[,j] <- inv.logit(det.prob)
}
# Create count predictions for each temp
for (j in seq_along(temp.vect)) {
det.prob <- DetectionIntercept + betaTemp*temp.vect[j] + betaTemp2*temp.vect[j]^2
matrix[,j] <- inv.logit(det.prob)
}
medians <- sapply(1:ncol(matrix), function(i) median(matrix[,i]))
CIs <- sapply(1:ncol(matrix), function(i) quantile(matrix[,i], c(0.025,0.975)))
temp.pred <- data.frame(Temp = temp.vect, Median = medians, L_CI = CIs[1, ], U_CI = CIs[2, ])
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
temp.vect
betaTemp
temp.vect.scaled
# Scale values the same way as in model
temp.vect.scaled = c(scale(temp.vect))
temp.vect.scaled
temp.vect = c(30:85)
# Scale values the same way as in model
temp.vect.scaled = c(scale(temp.vect))
# Make empty matrix for ??? draws over 469 surveys?
matrix <- matrix(NA, nrow=1500, ncol=56)
j=1
DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
inv.logit(det.prob)
seq_along(temp.vect.scaled)
temp.vect.scaled
temp.vect.scaled
j=temp.vect.scaled[1]
temp.vect.scaled[1:length(temp.vect.scaled)]
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
j=temp.vect.scaled[1]
j
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
dim(betaTemp)
j=1
temp.vect.scaled[j]
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
det.prob
# Create count predictions for each temp
for (j in 1:length(temp.vect.scaled)) {
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
matrix[,j] <- inv.logit(det.prob)
}
medians <- sapply(1:ncol(matrix), function(i) median(matrix[,i]))
CIs <- sapply(1:ncol(matrix), function(i) quantile(matrix[,i], c(0.025,0.975)))
temp.pred <- data.frame(Temp = temp.vect, Median = medians, L_CI = CIs[1, ], U_CI = CIs[2, ])
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
medians
CIs
Temp
temp.pred
medians <- sapply(1:ncol(matrix), function(i) median(matrix[,i]))
CIs <- sapply(1:ncol(matrix), function(i) quantile(matrix[,i], c(0.025,0.975)))
temp.pred <- data.frame(Temp = temp.vect.scaled, Median = medians, L_CI = CIs[1, ], U_CI = CIs[2, ])
temp.pred
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
1:length(temp.vect.scaled)
medians <- sapply(1:ncol(matrix), function(i) median(matrix[,i]))
CIs <- sapply(1:ncol(matrix), function(i) quantile(matrix[,i], c(0.025,0.975)))
temp.pred <- data.frame(Temp = c(1:length(temp.vect.scaled)), Median = medians, L_CI = CIs[1, ], U_CI = CIs[2, ])
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
library(ggplot2)
library(unmarked)
library(RColorBrewer)
library(tidyverse)
library(ggpattern)
setwd("\\Users\\jasmi\\OneDrive\\Documents\\OSU\\MS Docs\\OSS Data Pleth Conf 2023")
counts <- read.csv("OSS_data_2023_counts.csv")
climate <- read.csv("OSS_data_2023_climate.csv")
treatmentcount <- read.csv("OSS_data_2023_treatmentcount.csv")
treatmentcount.species <- read.csv("treatmentcount.species.csv")
temp <- read.csv("OSS_data_2023_temp.csv")
head(temp)
head(treatmentcount)
# Reshape the data for count by species
reshaped_data <- treatmentcount.species %>%
pivot_longer(cols = c(enes, oss), names_to = "species", values_to = "count")
barplot(counts$count,
space=1,
main="Counts by Date",
ylab="Daily Count",
xlab="month",
col=terrain.colors
(length(unique(counts$month)))
[as.factor(counts$month)])
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
barplot(counts$count,
space=1,
main="Counts by Date",
ylab="Daily Count",
xlab="month",
col=terrain.colors
(length(unique(counts$month)))
[as.factor(counts$month)])
plot(temp$ID~temp$Temp)
temps <- ggplot(temp, aes(x = ID, y = Temp, group = 1)) +
geom_point(color="blue") +
geom_line(color="blue", linewidth=2) +
theme_classic()+
theme(
panel.background = element_rect(fill='transparent'),
plot.background = element_rect(fill='transparent', color=NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.background = element_rect(fill='transparent'),
legend.box.background = element_rect(fill='transparent')
)
temps
# renaming and reordering the treatment intercepts for the boxplot
treatment_matrix <- TreatmentIntercept
new.names <- c("Salvage Logged", "Wildfire", "Harvest, Wildfire", "Harvest", "Control")
colnames(treatment_matrix) <- new.names
boxplot(treatment_matrix)
desired.order <- c("Control", "Wildfire", "Harvest, Wildfire", "Harvest", "Salvage Logged")
box.colors <- c('lightgreen','steelblue', 'coral2', '#f9d62e', '#b967ff' )
boxplot(treatment_matrix[, match(desired.order, colnames(treatment_matrix))],
main = "Treatment Intercepts for All Species",
xlab = "Treatment", ylab = "Occupancy Probability",
col = box.colors)
TreatmentIntercept
TreatmentIntercept[1]
TreatmentIntercept[2]
TreatmentIntercept[3]
TreatmentIntercept[4]
TreatmentIntercept[5]
trt.int.inv <- inv.logit(TreatmentIntercept)
trt.int.inv[1]
trt.int.inv[2]
trt.int.inv[3]
trt.int.inv[4]
trt.int.inv[5]
trt.int.inv[5]
treatment_matrix <- trt.int.inv
new.names <- c("Salvage Logged", "Wildfire", "Harvest, Wildfire", "Harvest", "Control")
colnames(treatment_matrix) <- new.names
boxplot(treatment_matrix)
desired.order <- c("Control", "Wildfire", "Harvest, Wildfire", "Harvest", "Salvage Logged")
box.colors <- c('lightgreen','steelblue', 'coral2', '#f9d62e', '#b967ff' )
boxplot(treatment_matrix[, match(desired.order, colnames(treatment_matrix))],
main = "Treatment Intercepts for All Species",
xlab = "Treatment", ylab = "Occupancy Probability",
col = box.colors)
treatment_matrix2 <- trt.int.inv # Using the inv logit treatment estimates
treatment_matrix
mean(trt.int.inv[1]) # 0.5409382  BS
mean(trt.int.inv[2]) # 0.5007341  BU
mean(trt.int.inv[3]) # 0.3617991  HB
mean(trt.int.inv[4]) # 0.4406697  HU
mean(trt.int.inv[5]) # 0.6406131  UU
mean(trt.int.inv[1]<0) # 0.5409382  BS
mean(trt.int.inv[1]>0) # 0.5409382  BS
mean(trt.int.inv[2]>0) # 0.5007341  BU
median(trt.int.inv[1]) # 0.5409382  BS
TreatmentIntercept
data2$treatment
treatment_matrix
hist(TreatmentIntercept[5])
hist(TreatmentIntercept[1])
TreatmentIntercept
## Assessing Convergence------------------------------------------------------------------------------------------------------
mcmcplot(mcmc.output.1$samples)
## Looking into Temp effect -----------------------------------------------------------------------------------------------
# need to predict across a range of temperature values to really see what's happening with these
hist(betaTemp)
hist(TreatmentIntercept[1])
hist(TreatmentIntercept[4])
hist(TreatmentIntercept[3])
class(TreatmentIntercept)
hist(TreatmentIntercept[,5])
hist(TreatmentIntercept[,3])
median(trt.int.inv[,1]) # 0.5409382  BS
mean(trt.int.inv[,2]) # 0.5007341  BU
mean(trt.int.inv[,3]) # 0.3617991  HB
mean(trt.int.inv[,4]) # 0.4406697  HU
mean(trt.int.inv[,5]) # 0.6406131  UU
TreatmentIntercept[,1] # 0.1641203
median(TreatmentIntercept[,1]) # 0.1641203
median(TreatmentIntercept[,2]) # 0.002936403
median(TreatmentIntercept[,3]) # -0.5675642
median(TreatmentIntercept[,4]) # -0.2384445
median(TreatmentIntercept[,4]) # -0.2384445
median(TreatmentIntercept[,5]) # 0.5780262
DetectionIntercept
median(trt.int.inv[,1]) # 0.125375    BS
median(trt.int.inv[,2]) # 4.383141    BU
median(trt.int.inv[,3]) # 1.057831    HB
median(trt.int.inv[,4]) # -0.2822513  HU
median(trt.int.inv[,5]) # 6.295515    UU
## Boxplot for Treatment Effects-----------------------------------------------------------------------------------------------
boxplot(TreatmentIntercept)
# Create count predictions for each temp
for (j in 30:85) {
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
matrix[,j] <- inv.logit(det.prob)
}
medians <- sapply(1:ncol(matrix), function(i) median(matrix[,i]))
# Create count predictions for each temp
for (j in 30:85) {
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
matrix[,j] <- inv.logit(det.prob)
}
# Create count predictions for each temp
for (j in 1:length(temp.vect.scaled)) {
det.prob <- DetectionIntercept + betaTemp*temp.vect.scaled[j] + betaTemp2*temp.vect.scaled[j]^2
matrix[,j] <- inv.logit(det.prob)
}
medians <- sapply(1:ncol(matrix), function(i) median(matrix[,i]))
CIs <- sapply(1:ncol(matrix), function(i) quantile(matrix[,i], c(0.025,0.975)))
temp.pred <- data.frame(Temp = c(30:85), Median = medians, L_CI = CIs[1, ], U_CI = CIs[2, ])
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
temp.pred <- data.frame(Temp = c(1:length(temp.vect.scaled)), Median = medians, L_CI = CIs[1, ], U_CI = CIs[2, ])
ggplot(temp.pred,aes(x = as.factor(Temp), y = Median)) +
geom_point() +
geom_ribbon(data=temp.pred, aes(x = Temp, ymin = L_CI, ymax = U_CI),inherit.aes=F,alpha=0.5)+
geom_line(data=temp.pred,aes(x=as.factor(Temp),y=Median)) +
labs(x = "Temp",
y = "Median Det Probability") +
theme_classic()
library(ggplot2)
library(unmarked)
library(RColorBrewer)
library(tidyverse)
library(ggpattern)
setwd("\\Users\\jasmi\\OneDrive\\Documents\\OSU\\MS Docs\\OSS Data Pleth Conf 2023")
setwd("/Users/jasmi/OneDrive/Documents/OSU/Projects/OSS Project/Analysis Pleth Conf 2023")
setwd("C:/Users/jasmi/OneDrive/Documents/OSU/Projects/OSS Project/Analysis Pleth Conf 2023")
setwd("~/Academic/OSU/Projects/OSS Project/Analysis Pleth Conf 2023")
setwd("~/Academic/OSU/Projects/OSS Project/Analysis Pleth Conf 2023")
counts <- read.csv("OSS_data_2023_counts.csv")
climate <- read.csv("OSS_data_2023_climate.csv")
treatmentcount <- read.csv("OSS_data_2023_treatmentcount.csv")
treatmentcount.species <- read.csv("treatmentcount.species.csv")
temp <- read.csv("OSS_data_2023_temp.csv")
head(temp)
head(treatmentcount)
# Reshape the data for count by species
reshaped_data <- treatmentcount.species %>%
pivot_longer(cols = c(enes, oss), names_to = "species", values_to = "count")
barplot(counts$count,
space=1,
main="Counts by Date",
ylab="Daily Count",
xlab="month",
col=terrain.colors
(length(unique(counts$month)))
[as.factor(counts$month)])
plot(temp$ID~temp$Temp)
temps <- ggplot(temp, aes(x = ID, y = Temp, group = 1)) +
geom_point(color="blue") +
geom_line(color="blue", linewidth=2) +
theme_classic()+
theme(
panel.background = element_rect(fill='transparent'),
plot.background = element_rect(fill='transparent', color=NA),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
legend.background = element_rect(fill='transparent'),
legend.box.background = element_rect(fill='transparent')
)
temps
ggsave("templine1.png", temps, bg="transparent")
# Boxplot by treatment
p1 <- ggplot(treatmentcount, aes(x=treatment, y=count, fill=treatment)) +
geom_boxplot(alpha=0.3) +
theme(legend.position="none") +
scale_fill_brewer(palette="Dark2")
p1
# Boxplot by treatment and species
p2 <- ggplot(reshaped_data, aes(x = treatment, y = count, fill = species)) +
geom_boxplot(position = position_dodge(width = 0.8), alpha = 0.3) +
scale_fill_brewer(palette = "Dark2") +
theme(legend.position = "top")
p2
# Create the boxplot with different colors for treatments and patterns for species
p3 <- ggplot(reshaped_data, aes(x = treatment, y = count, fill = treatment, linetype = species)) +
geom_boxplot(position = position_dodge(width = 0.8), alpha = 0.3) +
scale_fill_manual(values = scales::brewer_pal(palette = "Dark2")(n_distinct(reshaped_data$treatment))) +
scale_linetype_manual(values = c("solid", "dashed")) +
theme(legend.position = "top")
p3
#A single bar with enes and oss counts
ggplot(reshaped_data, aes(x=treatment, y=count, fill=treatment)) +
geom_bar(stat='identity', position='dodge') +
ggtitle('Salamander Counts by Treatment and Species') +
xlab('Treatment') +
ylab('Count')
#A bar for each spp, color fill by species
ggplot(reshaped_data, aes(x=treatment, y=count, fill=species)) +
geom_bar(stat='identity', position='dodge') +
ggtitle('Salamander Counts by Treatment and Species') +
xlab('Treatment') +
ylab('Count') +
scale_fill_manual('Species', values=c('coral2','steelblue'))
#Color fill by treatment, pattern by species
ggplot(reshaped_data, aes(x=treatment, y=count, fill=treatment, pattern=species)) +
geom_bar_pattern(stat='identity', position='dodge', pattern_fill="black") +
scale_fill_manual(values = c('BU' = 'red', 'HU' = 'blue', 'UU' = 'green', 'BS' = 'purple', 'HB' = 'orange')) +
scale_pattern_manual(values = c('oss' = 'stripe', 'enes' = 'none')) +
ggtitle('Salamander Counts by Treatment and Species') +
xlab('Treatment') +
ylab('Count')
ggplot(reshaped_data, aes(x=treatment, y=count, fill=treatment, pattern=species)) +
geom_bar_pattern(stat='identity', position='dodge', pattern_fill="black") +
scale_fill_brewer(palette = "Accent") +
ggtitle('Salamander Counts by Treatment and Species') +
xlab('Treatment') +
ylab('Count')
#Color fill by treatment, no patterns
ggplot(reshaped_data, aes(x=treatment, y=count, fill=treatment, pattern=species)) +
geom_bar_pattern(aes(pattern_density = species), stat='identity', position=position_dodge(width = 0.7),
pattern_fill="black", width = 0.8) +
scale_fill_brewer(palette = "Accent") +
scale_pattern_manual(values = c('oss' = 'none', 'enes' = 'none')) +
scale_pattern_density_manual(values = c('oss' = 0.3, 'enes' = 1)) +
ggtitle('Salamander Counts by Treatment and Species') +
xlab('Treatment') +
ylab('Count')
#A bar for each spp, color fill by species
ggplot(reshaped_data, aes(x=treatment, y=count, fill=species)) +
geom_bar(stat='identity', position='dodge') +
ggtitle('Salamander Counts by Treatment and Species') +
xlab('Treatment') +
ylab('Count') +
scale_fill_manual('Species', values=c('coral2','steelblue'))
